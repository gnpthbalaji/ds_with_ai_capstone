{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c81056",
   "metadata": {
    "id": "89c81056"
   },
   "source": [
    "# Intro to Data Science Bootcamp Capstone\n",
    "## Choose a project you care about, then use data to answer something real\n",
    "\n",
    "Welcome to the capstone. This is your chance to pick a topic that genuinely interests you and build a small, end‑to‑end data analytics project. “Analytics” can mean exploring and explaining patterns, forecasting, building a model, or creating a decision-support tool. The most important requirement is that you use data to answer a clear question and communicate your process and results well.\n",
    "\n",
    "This notebook is both an introduction and a starter template. You will replace the prompts with your own content as you go.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f17dbb3",
   "metadata": {
    "id": "0f17dbb3"
   },
   "source": [
    "## What you’re building\n",
    "By the end, you will deliver a short “portfolio-style” project with three parts: a well-defined question, a reproducible analysis (this notebook), and a clear explanation of what you found.\n",
    "\n",
    "You do not need a perfect model. You do need a coherent story: what you wanted to learn, what data you used, what you tried, what worked, what didn’t, and what you recommend next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47004d39",
   "metadata": {
    "id": "47004d39"
   },
   "source": [
    "## What counts as a capstone topic\n",
    "Your topic must be data analytics related and involve a dataset with enough rows/records to support analysis. You can pick something descriptive (what is happening), diagnostic (why is it happening), predictive (what will happen), or prescriptive (what should we do).\n",
    "\n",
    "Because we discussed a lot of machine learning, you may include ML if it helps answer your question. That said, strong projects often start with solid exploration and measurement before any modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89bcdf",
   "metadata": {
    "id": "5d89bcdf"
   },
   "source": [
    "## Suggested timeline\n",
    "You have one week for this project, so the focus is on making clear, intentional choices rather than building something huge. Early in the week should be spent picking a topic you care about, finding a usable dataset, and clearly defining your question. The middle of the week is for cleaning the data, doing exploratory analysis, and establishing a simple baseline approach. The end of the week is for iterating where it makes sense, evaluating your results, and polishing your narrative and visuals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339695c",
   "metadata": {
    "id": "3339695c"
   },
   "source": [
    "## Deliverables\n",
    "You will submit (1) this notebook with outputs saved, (2) a short written summary (one to two pages) or slide deck, and (3) your data source links and citation notes.\n",
    "\n",
    "Your notebook should run top-to-bottom without manual edits beyond setting a data path or API key (if used). If a dataset is too large to include, provide instructions for how to obtain it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054e9a0",
   "metadata": {
    "id": "5054e9a0"
   },
   "source": [
    "## How you’ll be evaluated\n",
    "A strong project is not “the fanciest model.” It is the clearest reasoning. The rubric below shows what matters.\n",
    "\n",
    "| Category | What “strong” looks like |\n",
    "|---|---|\n",
    "| Question and scope | A specific, answerable question; scope fits the timeframe |\n",
    "| Data | Data source is appropriate; data issues are acknowledged; columns are explained |\n",
    "| Methods | Choices match the question; baseline approach included; iterations are justified |\n",
    "| Evaluation | Clear metrics or validation; limitations discussed honestly |\n",
    "| Communication | Visuals and narrative tell a coherent story; reader can follow |\n",
    "| Reproducibility | Notebook runs; steps are documented; random seeds set when relevant |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8598132e",
   "metadata": {
    "id": "8598132e"
   },
   "source": [
    "## Project idea generator\n",
    "If you’re stuck, start with (1) a domain you care about, (2) an outcome you want to understand, and (3) a decision you want to support. Then translate that into a question the data can answer.\n",
    "\n",
    "Examples of domains include sports, music, movies, health (non-medical advice), fitness, finance (non-investment advice), retail, transportation, climate, education, gaming, social media, or your workplace (only if you have permission and can anonymize data).\n",
    "\n",
    "Below are idea prompts you can adapt. Each is written as a question plus a typical approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c64f97",
   "metadata": {
    "id": "b5c64f97"
   },
   "source": [
    "### Idea bank (pick one and customize it)\n",
    "| Theme | Example question | Typical approach |\n",
    "|---|---|---|\n",
    "| Consumer behavior | What factors predict repeat purchases or churn? | Cohort analysis, survival curves, logistic regression, tree models |\n",
    "| Pricing | How do price changes affect demand? | A/B-style comparisons, time series, elasticity estimates |\n",
    "| Sports analytics | What predicts wins or player performance? | Feature engineering, regression/classification, calibration |\n",
    "| Music/streaming | What drives playlist adds or skips? | EDA + classification, imbalance handling |\n",
    "| Job market | Which skills predict higher salaries in job postings? | NLP on descriptions, regression, explainability |\n",
    "| Transportation | What predicts late arrivals? | Time features, weather join, classification, error analysis |\n",
    "| Energy/climate | Can we forecast consumption or emissions? | Time series features, forecasting baselines, model comparison |\n",
    "| Public safety | Where and when do incidents cluster? | Mapping, clustering, hotspot analysis, seasonality |\n",
    "| Health behavior | What predicts adherence to a routine? | Segmentation, classification, interpretability |\n",
    "| Education | What predicts course completion? | Missingness analysis, fairness checks, classification |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c058b",
   "metadata": {
    "id": "788c058b"
   },
   "source": [
    "## Analytics-first mindset (even if you use ML)\n",
    "A simple way to keep your project grounded is to answer these in order. First, what does the data look like and what are the main patterns. Next, what changes over time, across groups, or across locations. Then, what features seem associated with your outcome. Only after that should you decide whether ML is necessary.\n",
    "\n",
    "If you do include machine learning, start with a baseline (for example a simple linear/logistic regression) before trying more complex models. Your report should explain why the complex model is worth it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0be0e",
   "metadata": {
    "id": "7bb0be0e"
   },
   "source": [
    "# Part 1. Project proposal (fill this in)\n",
    "Write in complete sentences. Being specific here will save you time later.\n",
    "\n",
    "## 1. Project title\n",
    "Choose a short title that suggests your question.\n",
    "\n",
    "## 2. Motivation\n",
    "What do you care about here. Who would use the results, or what decision could it inform.\n",
    "\n",
    "## 3. Research question\n",
    "State one primary question and optionally one secondary question.\n",
    "\n",
    "## 4. Data source\n",
    "Where does the data come from. Include a link and a brief description of how it was collected.\n",
    "\n",
    "## 5. Success criteria\n",
    "How will you know your project worked. This can be a metric, a useful insight, or a decision-support visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c90f6",
   "metadata": {
    "id": "718c90f6"
   },
   "source": [
    "# Part 2. Setup\n",
    "This section helps keep your work reproducible. Run these cells first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c043a03",
   "metadata": {
    "executionInfo": {
     "elapsed": 141,
     "status": "aborted",
     "timestamp": 1770485251307,
     "user": {
      "displayName": "Jeff Herman",
      "userId": "06894940112423514484"
     },
     "user_tz": 360
    },
    "id": "7c043a03"
   },
   "outputs": [],
   "source": [
    "# Core imports (add/remove as needed)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: uncomment if you use these\n",
    "# import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_absolute_error, accuracy_score, roc_auc_score\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922a485",
   "metadata": {
    "id": "b922a485"
   },
   "source": [
    "## Load your data\n",
    "Replace the example below with your dataset. Keep the raw data read step simple, then do cleaning in the next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f83c72",
   "metadata": {
    "executionInfo": {
     "elapsed": 154,
     "status": "aborted",
     "timestamp": 1770485251320,
     "user": {
      "displayName": "Jeff Herman",
      "userId": "06894940112423514484"
     },
     "user_tz": 360
    },
    "id": "01f83c72"
   },
   "outputs": [],
   "source": [
    "# Example: CSV\n",
    "# data_path = \"data/your_dataset.csv\"\n",
    "# df_raw = pd.read_csv(data_path)\n",
    "\n",
    "# Example: Parquet\n",
    "# df_raw = pd.read_parquet(\"data/your_dataset.parquet\")\n",
    "\n",
    "# If you are using an API, you can still cache the result to a file for reproducibility.\n",
    "\n",
    "df_raw = None  # replace this\n",
    "df_raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4414a45",
   "metadata": {
    "id": "b4414a45"
   },
   "source": [
    "# Part 3. Data audit\n",
    "Before cleaning, get a quick, honest read on what you have: size, columns, missing values, duplicates, and obvious data quality issues. Your write-up should mention any limitations you discover here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b12307",
   "metadata": {
    "executionInfo": {
     "elapsed": 162,
     "status": "aborted",
     "timestamp": 1770485251328,
     "user": {
      "displayName": "Jeff Herman",
      "userId": "06894940112423514484"
     },
     "user_tz": 360
    },
    "id": "02b12307"
   },
   "outputs": [],
   "source": [
    "def data_audit(df: pd.DataFrame, n_unique_preview: int = 8) -> pd.DataFrame:\n",
    "    summary = []\n",
    "    for col in df.columns:\n",
    "        s = df[col]\n",
    "        summary.append({\n",
    "            \"column\": col,\n",
    "            \"dtype\": str(s.dtype),\n",
    "            \"n_missing\": int(s.isna().sum()),\n",
    "            \"pct_missing\": float(s.isna().mean()),\n",
    "            \"n_unique\": int(s.nunique(dropna=True)),\n",
    "            \"example_values\": \", \".join(map(str, s.dropna().unique()[:n_unique_preview])),\n",
    "        })\n",
    "    out = pd.DataFrame(summary).sort_values([\"pct_missing\", \"n_unique\"], ascending=[False, True])\n",
    "    return out\n",
    "\n",
    "# Run after df_raw is loaded\n",
    "# audit = data_audit(df_raw)\n",
    "# audit.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38057b",
   "metadata": {
    "id": "cd38057b"
   },
   "source": [
    "# Part 4. Cleaning and feature prep\n",
    "Create a clean working dataframe called `df`. Keep your cleaning decisions transparent. If you drop rows, explain why. If you impute missing values, explain how.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ed31e",
   "metadata": {
    "executionInfo": {
     "elapsed": 163,
     "status": "aborted",
     "timestamp": 1770485251329,
     "user": {
      "displayName": "Jeff Herman",
      "userId": "06894940112423514484"
     },
     "user_tz": 360
    },
    "id": "420ed31e"
   },
   "outputs": [],
   "source": [
    "# df = df_raw.copy()\n",
    "\n",
    "# Typical steps (use what applies)\n",
    "# 1) Standardize column names\n",
    "# df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "# 2) Parse dates\n",
    "# df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# 3) Handle duplicates\n",
    "# df = df.drop_duplicates()\n",
    "\n",
    "# 4) Basic missingness handling\n",
    "# df = df.dropna(subset=[\"target_column\"])  # example\n",
    "\n",
    "# 5) Create features\n",
    "# df[\"day_of_week\"] = df[\"date\"].dt.day_name()\n",
    "\n",
    "df = None  # replace this\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b62a9e",
   "metadata": {
    "id": "b6b62a9e"
   },
   "source": [
    "# Part 5. Exploratory data analysis (EDA)\n",
    "Your goal here is to learn what’s typical, what’s weird, and what relationships might matter. EDA is also where you catch data leakage and target definition problems early.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd12ae6",
   "metadata": {
    "executionInfo": {
     "elapsed": 189,
     "status": "aborted",
     "timestamp": 1770485251355,
     "user": {
      "displayName": "Jeff Herman",
      "userId": "06894940112423514484"
     },
     "user_tz": 360
    },
    "id": "7fd12ae6"
   },
   "outputs": [],
   "source": [
    "# Examples you can adapt\n",
    "\n",
    "# 1) Basic shape\n",
    "# df.shape\n",
    "\n",
    "# 2) Quick numeric summary\n",
    "# df.describe(include=\"number\").T\n",
    "\n",
    "# 3) Quick categorical summary\n",
    "# df.describe(include=\"object\").T\n",
    "\n",
    "# 4) Simple plots (start with one variable at a time)\n",
    "# df[\"some_numeric_col\"].hist(bins=30)\n",
    "# plt.title(\"Distribution of ...\")\n",
    "# plt.show()\n",
    "\n",
    "# 5) Relationship to target (example)\n",
    "# df.plot.scatter(x=\"feature\", y=\"target\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb8de4",
   "metadata": {
    "id": "04bb8de4"
   },
   "source": [
    "# Part 6. Baseline approach\n",
    "Pick a baseline method that matches your question. If your project is descriptive, your baseline might be a clear set of summary stats and a simple dashboard-style figure. If you’re predicting a numeric value, a baseline can be “predict the mean” or a linear regression. If you’re predicting a class, a baseline can be “predict the majority class” or logistic regression.\n",
    "\n",
    "Write down what your baseline is and why it is a fair starting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09920a9f",
   "metadata": {
    "executionInfo": {
     "elapsed": 188,
     "status": "aborted",
     "timestamp": 1770485251355,
     "user": {
      "displayName": "Jeff Herman",
      "userId": "06894940112423514484"
     },
     "user_tz": 360
    },
    "id": "09920a9f"
   },
   "outputs": [],
   "source": [
    "# Put your baseline here.\n",
    "# If you model, define:\n",
    "# X, y, train/test split, a simple model, and a metric.\n",
    "\n",
    "# Example skeleton (classification):\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "#\n",
    "# y = df[\"target\"]\n",
    "# X = df.drop(columns=[\"target\"])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#\n",
    "# model = LogisticRegression(max_iter=200)\n",
    "# model.fit(X_train, y_train)\n",
    "# pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "# print(\"ROC AUC:\", roc_auc_score(y_test, pred_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a711b0",
   "metadata": {
    "id": "f2a711b0"
   },
   "source": [
    "# Part 7. Iteration and model comparison (optional but encouraged)\n",
    "If you include ML, compare at least two approaches and explain the tradeoffs. Use error analysis. Look at where the model fails. Consider whether features are causing leakage. Keep an eye on fairness issues if your data contains sensitive attributes or proxies.\n",
    "\n",
    "Even if you do not do ML, you can still iterate: try alternative groupings, alternative visualizations, or alternative definitions of your outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4062e53",
   "metadata": {
    "id": "b4062e53"
   },
   "source": [
    "# Part 8. Evaluation, limitations, and ethics\n",
    "Every project should include a clear evaluation. For non-ML projects, evaluation can be robustness checks, sensitivity analysis, or triangulation across different slices of the data. For ML projects, use appropriate metrics and a holdout set or cross-validation.\n",
    "\n",
    "Then list limitations honestly. Mention data coverage gaps, measurement issues, possible confounders, and how your approach might break in the real world.\n",
    "\n",
    "Finally, include a short ethics note. Identify any risks of harm, privacy concerns, or misuse, and how you mitigated them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f83a4",
   "metadata": {
    "id": "c24f83a4"
   },
   "source": [
    "# Part 9. Final story: what you found and what you recommend\n",
    "End with a short, readable conclusion. Imagine the audience is a smart manager or stakeholder who does not want to read code. Your last section should answer the question, show one or two key visuals, and propose next steps.\n",
    "\n",
    "A helpful structure is: what you asked, what data you used, what you found, what you recommend, and what you would do next with more time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f9864",
   "metadata": {
    "id": "442f9864"
   },
   "source": [
    "## Submission checklist\n",
    "Use this as a final pass. You can copy this into your written summary.\n",
    "\n",
    "Your notebook runs top-to-bottom. Your question is stated clearly near the top. Your data source is cited. Your cleaning steps are explained. Your EDA includes at least two useful figures. Your results are summarized in plain language. Your limitations and ethics note are included.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a59589",
   "metadata": {
    "id": "e5a59589"
   },
   "source": [
    "# Appendix: Where to find datasets\n",
    "If you do not already have data, these are reliable starting points. Choose one that fits your interest area and time constraints. When using public datasets, be sure you understand what each row represents and how the data was collected.\n",
    "\n",
    "Common sources include Kaggle datasets, data.gov (US), World Bank open data, city open data portals, NOAA climate data, Google Dataset Search, and sports/reference-style public stats sites. If you use web-scraped data, make sure you respect terms of service and keep your scrape gentle and legal.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
